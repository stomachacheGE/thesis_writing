%!TEX root = ThesisLKN.tex
\chapter{Introduction}

In recent years, more and more robots are deployed not only in industrial environments but also human populated areas. In order to fulfill their tasks, it is necessary for robots to interact and even cooperate with people. Therefore, tracking the location of people in those environments has gained enormous attentions in robotics community. Besides, with the increasing popularity of artificial intelligence, robots are also expected to be intelligent enough to predict possible future locations of walking human even when encountered with occlusions or missing of sensor data. Enabled by accurate tracking and prediction of human movements, robots are able to have a better understanding of the environment, which will facilitate interactions between robots and humans.

The very fist requirement for a robot to operate is to model the environment. A simple yet effective way is to use occupancy grid map representation of the environment \citep{elfes1989using}. It decomposes the environment into cells with a predefined resolution, and the state of each cell is a random variable with values of either \textit{occupied} or \textit{not occupied}. This representation has been extensively used in many different kinds of robot tasks like simultaneous localization and mapping (SLAM). The classical grid map representation treats the environment as static, which is not always the case in real scenarios. In other words, the environment can be dynamic since objects can move around in the environment. Object tracking addresses dynamics in environment explicitly, since it tracks and predicts how objects move. If there is more than one object involved at the same time, the tracking problem becomes multiple object tracking (MOT). In human tracking systems, the dynamics in environment refer to changes of humans' location along the time horizon (i.e., trajectories). 

Commonly, a tracking system is implemented as a multiple stage pipeline, which consists of object detection, data association, motion modeling and occupancy generation. When dealing with a multiple object tracking problem, data association becomes very tricky. The classical way to perform data association is to maintain a list of known objects, and associates new observations with those existing objects. The main difficulty of this approach is to deal with \textit{birth} (whether observation is from a new object) and \textit{death} (whether a maintained object should be deleted) of tracks \citep{gauvrit1997formulation}. 

To address the data association problem, \citet{coue2006bayesian} proposed \textit{Bayesian occupancy filter} (BOF), which is an object tracking algorithm based on grid map representation of the environment. It essentially avoids data association step in the tracking pipeline, since concepts of \textit{objects} and \textit{tracks} does not exist in BOF framework. Rather than treat tracking problem from an \textit{object} point of view, BOF addresses tracking from a \textit{cell} perspective. That is to say, tracks are replaced by transitions of occupancies between cells over time. Meanwhile, BOF is robust to object occlusion thanks to the combination of \textit{prediction} and \textit{estimation} steps. This two-step mechanism is well suited for handling the consistency between occupancy predictions and new observations, therefore uncertainties incurred by occlusion are naturally handled in a probabilistic way. Over the past few years, there has been some extensions over BOF proposed in literature \citep{gindele2009bayesian, brechtel2010recursive, llamazares2013dynamic}. 

\begin{figure}[H]
  \centering
    \includegraphics[width=.5\textwidth]{figures/roundabout.png}
    \caption[An illustration of a round-about]{Illustration of a round-about. Cars can only drive in directions indicated by red arrows. The green rectangle represents a car at that location. Since we know that the car must drive in the specified directions, the possible locations of the car after a few time steps are indicated by the two green ellipses. This prior knowledge helps us to track the dynamic objects since we have better chances to locate the car according to its motion pattern.}
    \label{fig:roundabout_idea}
\end{figure}

A tracking system usually predicts the state of the world (e.g., object location and velocity) based on past observations. Many tracking algorithms also incorporate motion model of the objects being tracked, since this allows them to utilize prior knowledge of object's motion cues. As an intuitive example, let us consider a round-about as shown in Figure \ref{fig:roundabout_idea}, where cars can only drive in one direction. To track a car driving in a round-about, predictions of future possible locations of the car should always be on the side which allowed driving direction indicates. Likewise, human tracking in indoor environments can also benefit from human motion patterns. For BOF and its variants, the objects being tracked are assumed to perform linear motion, which indicates that objects always move in the same direction as in the last time step. Although \citet{gindele2009bayesian} proposed to incorporate prior map knowledge (BOFUM) to better model the motion dynamics based on cell context, the underlying linear motion is too simplistic to model actual human motion in indoor environments. 

Based on our observations of human trajectories, we found two aspects very important for explaining human motion: 1) Unlike in free space, people have to move under spatial constraints in indoor environments. For example, people tend to walk along the central area between walls in a corridor and change their walking directions when they have to make turns. That is to say, the spatial configuration puts constraints on human motion patterns and therefore human motion is very place dependent. 2) People move continuously in time and space, which means they do not disappear or appear out of thin air. If a person is currently located at a cell on a grid map, he or she has to walk through its neighboring cells first. In other words, future state of a cell is highly influenced by state changes of its neighboring cells. These observations motivates us to model human motion in a way that captures both \textbf{place dependency} as well as \textbf{spatial correlation} between cells.

In computer vision community, machine learning has shown a lot of successes over last few years . Image classification algorithms based on convolutional neural networks (CNNs) won all ImageNet classification challenges since 2012 \citep{russakovsky2015imagenet}. It turns out that CNNs achieve good results in not only computer vision tasks but also many other domains. For example, recurrent neural networks (RNNs) can be applied in automatic language translation \citep{cho2014learning}. Deep reinforcement learning are good choice for teaching robots to perform human actions like grasping\citep{levine2016learning}. Essentially, the reason why CNN works in those domains is that it is able to capture complex structures in data. Once a CNN learns these structures, it can generalize to cases that never occur during training. 

In order to utilize the powerful generalization abilities of CNNs, we proposed to model motion patterns in a way that can be expressed as the output of a CNN. By this way, if we feed a grid map as input and human motion pattern as ground truth to a network, it is able to learn the pattern after training with lots of data. We model human motion patterns as a set of conditional probabilities for every cell on the map. They represent how likely a person moves to one of the neighboring cells, conditioned on which neighboring cell he or she comes from. Since these probabilities incorporate information about the incoming cell, the motion model captures spatial correlations between cells. Besides, they are different for each cell based on cell's context on the map, which means that the learned motion pattern is expressive enough to predict different motions at different locations. In other words, our motion model is also place dependent. In fact, similar idea of making motion patterns place dependent has been proposed by \cite{kucner2013conditional}, but in order to learn motion pattern on a map, they need sensor observations from that specific map. In other words, their method lacks generalization ability. 

\begin{figure}[H]
  \centering
    \includegraphics[width=.6\textwidth]{figures/theme_plot_1.png}
    \caption[An example of future occupancy predictions of our method.]{An example of future occupancy predictions of our method.  The map shows a Y-fork, where only white spaces are walkable. Initially, a person is shown as a red rectangle and with velocity towards left. Since no further sensor reading is given, BOFMP propagates occupancies over time. After some time interval, most occupancies appear in both upper and lower branches of the corridor, which proves that our motion model successfully learns that people tend to make turns at the intersection. Besides, BOFMP predicts more occupancies in the middle of corridors, since it learned that people are less likely to walk near walls.}
    \label{fig:intro_idea}
\end{figure}

The data we use for training network is generated from simulated human trajectories on SLAM-generated maps of real world offices. Once the network finishes learning, we can feed new maps to the network and obtain human motion patterns from network output. These motion patterns are then incorporated into the BOF framework to perform human tracking in indoor environments. We call our tracking method \textit{Bayesian Occupancy Filter with Motion Patterns} (BOFMP). If only initial state of a person is given and no further observations are provided, our method is able to predict reachable areas after some time steps. Figure \ref{fig:intro_idea} shows an example of future occupancy predictions of our method without sensor observations. It shows that our way of modeling human motion patterns enables BOF to propagate occupancies to reasonable areas.

The main contributions of this thesis are:

\begin{my_enumerate}
\item We present a way of modeling human motion patterns that captures both place dependency and spatial correlations between cells. Besides, thanks to powerful generalization abilities of CNNs, our method can generate motion patterns on maps that are never seen by our network.
\item We incorporate the learned motion patterns into BOF framework seamlessly for human tracking in indoor environments, and achieve better tracking performance than the baseline method.  The whole pipeline of modeling motion patterns and tracking of dynamic objects presented in this thesis work can be applied in other scenarios, such as car tracking in ADAS systems.
\end{my_enumerate}


The rest of this thesis is organized as follows: Chapter \ref{chapter:2} summarizes the related works and highlights the similarities and differences between our method and others in literature. Chapter \ref{chapter:3} introduces mathematical formulation of BOFMP and discusses how the network structure used in thesis is derived. Chapter \ref{chapter:4} talks about some details on the implementations, such as simulation of human walking trajectories and the code structure of BOFMP. Chapter \ref{chapter:5} summarizes the dataset and presents the tracking performance of our method and its baseline. Chapter \ref{chapter:6} concludes the thesis and presents possible improvements on our method. 
